<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Facheng Yu</title>
  
  <meta name="author" content="Facheng Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Facheng Yu</name>
              </p>
              <p>Hi! I am a third year undergraduate in <a href="http://maths.whu.edu.cn/Englishversion/index.htm">School of Mathematics and Statistics</a>, <a href="https://en.whu.edu.cn"></a>.
                I am going to recieve my bachelor degree in June, 2023. 
              </p>
              <p>Currently <b style="color:orange">I am seeking for a phd position</b> in data science, machine learning and computer vision.
              </p>
              <p style="text-align:center">
                    [
                <a href="mailto:yufacheng@whu.edu.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/fachengyu/">Github</a> &nbsp/&nbsp
                <a href="images/yfc_cv.pdf">CV</a>
]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yfc.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yfc.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->
        <p> 
        <!-- with <a href="https://webdocs.cs.ualberta.ca/~dale/">Dale Schuurmans</a> and <a href="https://www.afaust.info/">Aleksandra Faust</a> in similar areas. --> 
        <!-- I was fortunate to also work on consumer privacy rights and legislation with folks from <a href="https://www.law.georgetown.edu/privacy-technology-center">Georgetown's Center on Privacy and Technology.</a></p> -->
              </p>
              <p>
          
              </p>
        <h2>News</h2>

            <ul>
                <li><b>December 2021</b>: <b style="color:red">Prize</b> - Won a 3nd prize of the Asia and Pacific Mathematical Contest in Modeling of the undergraduate group.</li>
                <li><b>December 2021</b>: <b style="color:red">Prize</b> - Won a 2nd prize of the Big Data Competitions of Colleges in China.</li>
                <li><b>November 2021</b>: <b style="color:red">Prize</b> - Won a 3rd prize of the Chinese Mathematics Competitions again.</li>
                <li><b>October 2021</b>: <b style="color:red">Internship</b> - Joined <a href="https://cvrs.whu.edu.cn">Computer Vision & Remote Sensing Lab, Wuhan University</a>, supervised by <a href="https://cvrs.whu.edu.cn/jianyao/">Prof. Jian Yao</a>.</li>
                <li><b>October 2021</b>: <b style="color:red">Scholarship</b> - Won a 2nd outstanding students' scholarship of Wuhan Univeristy.</li>
                <li><b>Augest 2021</b>: <b style="color:red">Online project</b> - Finished the multi-agent reinforcement learning online project, supervised by <a href="https://www.cl.cam.ac.uk/~pl219/">Prof. Pietro Li√≤</a>.</li>
                <li><b>February 2021</b>: <b style="color:red">Online project</b> - Finished the theoretical neuroscience online project, supervised by <a href="https://www.neuroscience.cam.ac.uk/directory/profile.php?gje.hennequin">Prof. Guillaume Hennequin</a>.</li>
                <li><b>November 2020</b>: <b style="color:red">Prize</b> - Won a 3rd prize of the Chinese Mathematics Competitions.</li>
                <li><b>October 2020</b>: <b style="color:red">Scholarship</b> - Won a 3rd outstanding students' scholarship of Wuhan Univeristy.</li>  
                <li><b>June 2020</b>: <b style="color:red">Online school</b> - Took the online summer school of<a href="https://ymsc.tsinghua.edu.cn/en/">Yau Mathematical Science Center, Tsinghua University</a>, studying big data analysis.</li>
                <li><b>September 2019</b>: <b style="color:red">Undergraduate study</b> - Began my undergraduate in <a href="http://maths.whu.edu.cn/Englishversion/index.htm">School of Mathematics and Statistics, Wuhan University</a>, majoring in mathematics and applied mathematics.</li>
            </ul>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <!--
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/todo.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="todo_link">
                <papertitle>TODO_paper_title</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              TODO,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>
              <br>
              <em>TODO conference venue</em>. 
              <br>
              <p>TODO tldr</p>
            </td>
          </tr>
                -->
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/kts.png" alt="kts" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="todo_link">
                <papertitle>Know Thy Student: Interactive Learning with Gaussian Processes</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              <a href="https://www.mikehwu.com/">Mike Wu</a>,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>
              <br>
              <em>ICLR 2022 Workshop on From Cells to Societies: Collective Learning across Scales</em>. 
              <br>
              [
              <a href="https://openreview.net/pdf?id=rpGGNrMJpW9">Paper</a> 
               ]
              <br>
              <p>
              Learning often involves interaction between multiple agents. 
                Human teacher-student settings best illustrate how interactions result in efficient knowledge passing where the teacher constructs a curriculum based on their students' abilities. 
                Prior work in machine teaching studies how the teacher should construct optimal teaching datasets assuming the teacher knows everything about the student.
                However, in the real world, the teacher doesn't have complete information and must probe before teaching.
                Our work proposes a simple probing algorithm which uses Gaussian processes for inferring student-related information, before constructing a teaching dataset.
                Our experiments highlight the importance of probing before teaching, 
                demonstrate how students can learn much more efficiently with the help of an interactive teacher, and outline where probing combined with machine teaching would be more desirable than passive learning. 
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lm_via_sp.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=pMQwKL1yctf">
                  <papertitle>Language modeling via stochastic processes</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              <a href="https://esdurmus.github.io/">Esin Durmus</a>,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>,
              <a href="https://thashim.github.io/">Tatsunori Hashimoto</a>,
              <br>
              <em>International Conference for Learning Representations (ICLR) 2022</em>. 
              <br>
              <b style="color:red">Oral Presentation (1.6% oral acceptance rate)</b>
              <br>
              [
              <a href="https://openreview.net/forum?id=pMQwKL1yctf">Paper</a> /
              <a href="https://www.youtube.com/watch?v=AwnoASlxeIs&t=13s&ab_channel=RoseWang">Video</a> /
              <a href="https://github.com/rosewang2008/language_modeling_via_stochastic_processes">Code</a> ]
              <br>
              <p>Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan.</p>
            </td>
          </tr>
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cyl.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2110.05422.pdf">
                <papertitle>Calibrate your listeners! Robust communication-based training for pragmatic speakers</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              Julia White,
              <a href="https://cs.stanford.edu/~muj/">Jesse Mu</a>,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>
              <br>
              <em>Findings of EMNLP 2021</em>. 
              <br>
              [
              <a href="https://arxiv.org/pdf/2110.05422.pdf">Paper</a> /
              <a href="https://github.com/rosewang2008/calibrate_your_listeners">Video</a> /
              <a href="https://github.com/rosewang2008/calibrate_your_listeners">Code</a> ]
              <p> To be good conversational partners, natural language processing (NLP) systems should be trained to produce contextually useful utterances. Prior work has investigated training NLP systems with communication-based objectives, where a neural listener stands in as a communication partner. However, these systems commonly suffer from semantic drift where the learned language diverges radically from natural language. We propose a method that uses a population of neural listeners to regularize speaker training.</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fm.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2108.07258.pdf">
                <papertitle>On the opportunities and risks of foundation models</papertitle>
              </a>
              <br>
              Many authors...,
              <strong>Rose E. Wang</strong>,
              more authors,...
              <br>
              <em>August 2021</em>. 
              <br>
              <p>This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical
              considerations)..</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/adhoc.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.11778">
                <papertitle>Too many cooks: Bayesian inference for coordinating multi-agent collaboration</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang*</strong>,
              Sarah Wu*,
              <a href="https://sociology.uchicago.edu/directory/james-evans">James A. Evans</a>,
              <a href="http://web.mit.edu/cocosci/josh.html">Joshua B. Tenenbaum</a>,
              <a href="https://www.eecs.harvard.edu/~parkes/">David C. Parkes</a>,
              <a href="http://www.mit.edu/~maxkw/">Max Kleiman-Weiner</a>
              <br>
              <em>Journal of the Cognitive Science Society, April 2021</em>. 
              <br>
              <em>NeurIPS 2020 Cooperative AI workshop</em>. 
              <br>
              <b style="color:red">Won best paper award at NeurIPS 2020 Cooperative AI Workshop!</b>
              <br>
              [
              <a href="https://arxiv.org/abs/2003.11778">Paper</a> /
              <a href="https://www.youtube.com/watch?v=Fd4RcVaNthY">Video</a> /
              <a href="https://github.com/rosewang2008/gym-cooking">Code</a> ]
              <p>We develop Bayesian Delegation, a decentralized multi-agent learning mechanism that enables agents to rapidly infer the sub-tasks of others by inverse planning. We demonstrate that our model is a capable ad-hoc collaborator, scales with team size and makes inferences about intent similar to human observers.</p>
            </td>
          </tr>
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hpp.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.06906">
                <papertitle>Model-based Reinforcement Learning for Multiagent Goal Alignment</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              <a href="https://research.google/people/JChaseKew/">J.Chase Kew</a>,
              <a href="https://scholar.google.com/citations?user=vOLXDDAAAAAJ&hl=en">Dennis Lee</a>,
              <a href="https://deepai.org/profile/tsang-wei-edward-lee">Tsang-Wei Edward Lee</a>,
              <a href="https://research.google/people/TingnanZhang/">Tingnan Zhang</a>,
              <a href="http://brianichter.com/">Brian Ichter</a>,
              <a href="http://www.jie-tan.net/">Jie Tan</a>,
              <a href="https://www.afaust.info/">Aleksandra Faust</a>
              <br>
              <em>Conference on Robot Learning (CoRL) 2020</em>.<br>
              <em>Mentioned in <a href="https://ai.googleblog.com/2021/01/google-research-looking-back-at-2020.html">Google AI Year in Review, 2020</a>.</em><br> 
                [
              <a href="https://arxiv.org/abs/2003.06906">Paper</a> /
              <a href="https://www.youtube.com/watch?v=-LqgfksqNH8&feature=youtu.be">Video</a> /
              <a href="https://sites.google.com/view/multiagent-hpp">Project Page</a> / 
              <a href="https://ai.googleblog.com/2021/04/model-based-rl-for-decentralized-multi.html">Blog post</a>
              ]
              <br>
              <p></p>
              <p>In this work, we present hierarchical predictive planning (HPP) for decentralized multiagent navigation tasks. Our approach is trained in simulation and works in unseen settings both in simulation and in the real world (zero shot transfer)!</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/overcooked.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.11778">
                <papertitle>Too many cooks: Coordinating multi-agent collaboration through inverse planning</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang*</strong>,
              Sarah Wu*,
              <a href="https://sociology.uchicago.edu/directory/james-evans">James A. Evans</a>,
              <a href="http://web.mit.edu/cocosci/josh.html">Joshua B. Tenenbaum</a>,
              <a href="https://www.eecs.harvard.edu/~parkes/">David C. Parkes</a>,
              <a href="http://www.mit.edu/~maxkw/">Max Kleiman-Weiner</a>
              <br>
              <em>Human-Like Machine Intelligence (book published with Oxford University Press)</em><br>
              <em>Annual Meeting of the Cognitive Science Society (CogSci) 2020</em><br>
              <em>International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2020</em><br>
              <em>Invited paper to OptLearnMAS Workshop at AAMAS 2020</em><br> 
              <b style="color:red">Won best paper award for Computational Modeling for Higher Cognition at CogSci 2020!</b>
              <br>
                [
              <a href="https://arxiv.org/abs/2003.11778">Paper</a> / 
              <a href="https://www.youtube.com/watch?v=Fd4RcVaNthY">Video</a> /
              <a href="https://github.com/rosewang2008/gym-cooking">Code</a>
              ]
              <p>We develop Bayesian Delegation, a decentralized multi-agent learning mechanism that enables agents to rapidly infer the sub-tasks of others by inverse planning.</p>
            </td>
          </tr>
          
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rmaddpg.png" alt="rmaddpg" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2002.06684">
                <papertitle>R-MADDPG for Partially Observable Environments and Limited Communication</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              <a href="http://mfe.scripts.mit.edu/portfolio/">Michael Everett</a>,
              <a href="http://www.mit.edu/people/jhow/">Jonathan P. How</a>
              <br>
              <em>International Conference on Machine Learning (ICML) 2019, Reinforcement Learning for Real Life Workshop</em>
              <br>
                [
              <a href="https://arxiv.org/abs/2002.06684">Paper</a> /
              <a href="https://github.com/rosewang2008/rmaddpg">Code</a> /
              <a href="https://sites.google.com/view/rmaddpg/home?authuser=0">Project Page</a>
                    ]
              <br>
              <p></p>
              <p>This paper introduces a deep recurrent multiagent actor-critic framework (R-MADDPG) for handling multiagent coordination under partial observable settings and limited communication.</p>
            </td>
          </tr>

          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rc66.jpg" alt="rc66" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.youtube.com/watch?v=dkhRkWSc8Xw&feature=youtu.be">
                <papertitle>DRIV3N: Race to Autonomy</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>, Austin Floyd, Marwa Abdulhai, Luxas Novak, David Klee, Sean Patrick Kelley
              <br>
              <em>Robotics: Science and Systems I</em>, 2017. 
              <br>
                [
              <a href="https://www.youtube.com/watch?v=dkhRkWSc8Xw&feature=youtu.be">Video</a> /
              <a href="https://rosewang2008.github.io/rss-team3/">Project Page</a>
              ]
              <br>
              <p></p>
              <p>A whirlwind of an experience where my team and I developed a <b>fast</b>, <i>autonomous</i>, ~maze-solving~ racecars equipped with no machine learning technology and a decorative safety controller.</p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
  Template from <a href="https://jonbarron.info/">this website</a>.
</body>

</html>
