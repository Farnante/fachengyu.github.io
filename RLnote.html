<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Facheng Yu</title>
  
  <meta name="author" content="Facheng Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <h2>About website</h2>
        <p>Here are my notes while learning <em>CS 6789: Foundations of Reinforcement Learning</em>.
        </p>
        <p> Lastest update: 8/1/2022
        </p>
      </td>
    </tr>
  </table>
 
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        
        <h2>Content</h2>
        <ul> <li><b>Charper 1</b></li>
            <ul>
                <li>Section 1.1: <a href="RLnotes/1-1.pdf">Discounted Markov Decision Processes</a>.</li>
                <li>Section 1.2: <a href="RLnotes/1-2.pdf">Finite-Horizon Markov Decision Processes</a>.</li>
                <li>Section 1.3a: <a href="RLnotes/1-3a.pdf">Value Iteration and Policy Iteration</a>.</li>
                <li>Section 1.3b: <a href="RLnotes/1-3a.pdf">Value Iteration for Finite Horizon MDP and Linear Programming Approach</a>.</li>
            </ul>
        </ul>
        
      </td>
    </tr>
  </table>

</body>

</html>
